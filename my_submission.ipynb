{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "users = pd.read_csv(\"data/users.csv\")\n",
    "movies = pd.read_csv(\"data/movies.csv\")\n",
    "ratings = pd.read_csv(\"data/ratings.csv\")\n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'movie_id', 'rating'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class Recommender_System_Movies_DataSet():\n",
    "\n",
    "    def __init__(self, ratings: pandas.DataFrame, movies: pandas.DataFrame,\n",
    "                 users: pandas.DataFrame):\n",
    "\n",
    "\n",
    "        self.movies  = movies\n",
    "        self.ratings = ratings\n",
    "        self.users    = users\n",
    "        \n",
    "    def get_recommendations(self,user_id: int, k: int):\n",
    "        \n",
    "        \"\"\"Recommends the k most similar movies of the movie with the id 'movie_id'.\n",
    "        Parameters\n",
    "        ----------\n",
    "        movie_id :The id of the movie.\n",
    "        k : int The number of similar movies to recommend.\n",
    "        Returns: list of movie ids     \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        def content_filtering(movies,user_id,k):\n",
    "            \n",
    "           \n",
    "            \n",
    "            df=movies.copy() \n",
    "            df.set_index('movie_id')\n",
    "            # setting movie id as index in case table has movie_ids not in order\n",
    "            df=df.drop(columns = ['title','year'])\n",
    "            \n",
    "            # I am finding cosine similarity matrix \n",
    "            from sklearn.metrics.pairwise import cosine_similarity\n",
    "            similarity_matrix = pd.DataFrame(cosine_similarity(df))\n",
    "            \n",
    "            \n",
    "\n",
    "            # finding movies liked by user with user_id so that recommendation can be made on those movies \n",
    "            # I am making one recommendation per 5 or 4 rated movie thus giving variation in reommnedation \n",
    "\n",
    "            movies_liked_by_user = ratings[ratings['user_id'] == user_id].sort_values(by='rating', ascending=False)\n",
    "            movies_liked_by_user_list= list(movies_liked_by_user['movie_id'])\n",
    "            \n",
    "            \n",
    "            # checking if we have 4 or 5 rated movies for that user \n",
    "            movies_liked_by_user_rated_4_or_5 = movies_liked_by_user[movies_liked_by_user['rating']>=4]\n",
    "            if len(movies_liked_by_user_rated_4_or_5)<k:\n",
    "                less_rating_avilable= True\n",
    "            else:less_rating_avilable= False\n",
    "                \n",
    "            # if yes then we ill be recommending one movie from one rating rather than recommending more based on same movie\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "            Recommend= list()\n",
    "            # this list will contain the movie ids we will recommend by this filtering method \n",
    "            \n",
    "            \n",
    "            if less_rating_avilable==False:\n",
    "                for i in movies_liked_by_user_list:\n",
    "                    while len(Recommend)!=k:\n",
    "                        # finding the movie_ids that have highere cosine similarity \n",
    "                        \n",
    "                        elements= similarity_matrix.loc[i].tolist()\n",
    "                        index_numbers = np.argsort(elements).tolist()\n",
    "                        l = len(index_numbers)\n",
    "                        \n",
    "                        for j in range(l):\n",
    "                            temp=index_numbers[l-1-j] \n",
    "                            #since after agsoert the index with higher cosine similarity would be at end of list\n",
    "                            \n",
    "                            if (temp not in Recommend) and ( temp not in movies_liked_by_user) :\n",
    "                                \n",
    "                                            \n",
    "                                \"\"\" \n",
    "                                The movies already present in rating table are watched by this user\n",
    "                                hence we will not be including them here so if condition and also checking if \n",
    "                                the movie is not already recommended earlier\n",
    "\n",
    "                               \"\"\"\n",
    "                            \n",
    "                                Recommend.append(temp)\n",
    "                                break\n",
    "                            else: continue\n",
    "                                \n",
    "                                \n",
    "            else:\n",
    "                # for the case we don't have enough 4 or 5 rated movies\n",
    "                while len(Recommend)!=k:\n",
    "                    \n",
    "             # basically if we have less high rated movies hence checking two movies per rated movie where rating <=3\n",
    "            # we are recommending two movies per rated movie \n",
    "                    \n",
    "                    movies_liked_by_user_above_3= list([movies_liked_by_user['rating']>=3]['movie_id'])\n",
    "                    \n",
    "                    # in case there are no ratings provided by user above 3\n",
    "                    if len(movies_liked_by_user_above_3)==0: \n",
    "                        print( 'for the user_id {} not encough ratings given by user').format(user_id)\n",
    "                    else:\n",
    "                        for i in movies_liked_by_user_below_3:\n",
    "                            elements= similarity_matrix.loc[i].tolist()\n",
    "                            index_numbers = np.argsort(element).tolist()\n",
    "                            l = len(index_numbers)\n",
    "                            count=0\n",
    "                            # counter used for every movie makes two recommendations as we don't have enough high ratings given by user\n",
    "                            for j in range(l):\n",
    "                                temp=index_numbers[l-1-j] \n",
    "                                if temp not in Recommend and ( temp not in movies_liked_by_user):\n",
    "                                    Recommend.append(temp)\n",
    "                                    if count==2: break\n",
    "                                else: continue\n",
    "\n",
    "\n",
    "            return Recommend\n",
    "        \n",
    "        \n",
    "        def collabrative_filltering(rating,user_id,k):\n",
    "            \n",
    "            #each unique value is assigned a number from zeroi.e, category code\n",
    "            ratings.user_id = ratings.user_id.astype('category').cat.codes.values\n",
    "            ratings.movie_id = ratings.movie_id.astype('category').cat.codes.values\n",
    "\n",
    "            #split the data set\n",
    "            from sklearn.model_selection import train_test_split\n",
    "            train, test = train_test_split(ratings, test_size=0.2)\n",
    "\n",
    "            #number of users and movies\n",
    "            n_users, n_movies = len(ratings.user_id.unique()), len(ratings.movie_id.unique())\n",
    "            n_latent_factors = 3\n",
    "\n",
    "            #create movie input of n movies * 1 coulmn\n",
    "            movie_input = keras.layers.Input(shape = [1], name = 'item')\n",
    "            # create embedding vector space of n_movies * n_latent_factors\n",
    "            movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name = 'movie_emb')(movie_input)\n",
    "            #flatten into single vector \n",
    "            movie_vec = keras.layers.Flatten(name = \"Flatten_Movies\")(movie_embedding)\n",
    "\n",
    "\n",
    "            user_input = keras.layers.Input(shape = [1], name = \"User\")\n",
    "            user_vec = keras.layers.Flatten(name = 'Flatten_Users')(keras.layers.Embedding(n_users + 1, n_latent_factors,\n",
    "                                                                                            name = 'user_emb')(user_input))\n",
    "\n",
    "            prod = keras.layers.dot([movie_vec, user_vec], axes = 1, name = \"Dot_Product\")\n",
    "\n",
    "            model = keras.Model([user_input, movie_input], prod)\n",
    "\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse'])\n",
    "            model.summary()\n",
    "\n",
    "            # I have used 20 epochs but at 100 results are better \n",
    "            history = model.fit([train.user_id, train.movie_id], train.rating, epochs=30, verbose=1)\n",
    "\n",
    "            \"\"\"\n",
    "            to display result graph use this \n",
    "            import matplotlib.pyplot as plt\n",
    "\n",
    "            pd.Series(history.history['loss']).plot(logy=True)\n",
    "            plt.xlabel(\"Epoch\")\n",
    "            plt.ylabel(\"Training Error\")\n",
    "\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "            # check for error on test \n",
    "                \n",
    "            y_hat_2 = np.round(model.predict([test.user_id, test.movie_id]))\n",
    "            from sklearn.metrics import mean_absolute_error\n",
    "            y_true = test.rating\n",
    "            print(mean_absolute_error(y_true, y_hat_2))\n",
    "            print(mean_absolute_error(y_true, model.predict([test.user_id, test.movie_id])))\n",
    "\n",
    "            #learnt embedding layer\n",
    "\n",
    "            user_embedding_learnt = model.get_layer(name='user_emb').get_weights()[0]\n",
    "            movie_embedding_learnt = model.get_layer(name='movie_emb').get_weights()[0]\n",
    "\n",
    "            movies_now = user_embedding_learnt[user_id]@movie_embedding_learnt.T\n",
    "            Recommend = list(np.argpartition(movies_now, -k)[-k:])\n",
    "\n",
    "            return Recommend\n",
    "        \n",
    "        def Hybrid_Modelling(content, collabarative, movies, k):\n",
    "            final=list()\n",
    "            #first the movie_id common in both collabrative and content they would be taken\n",
    "            for i in content:\n",
    "                if i in collabarative:\n",
    "                    final.append(i)\n",
    "            if len(final)!=0 and len(final)!=k:\n",
    "                for i in final:\n",
    "                    content.remove(i)\n",
    "                    collabarative.remove(i)\n",
    "\n",
    "\n",
    "                for j in range(k-len(final)):\n",
    "                    if len(final)!=k:\n",
    "                        final.append(content[j])\n",
    "                        if len(final)!=k:  \n",
    "                            final.append(collabarative[j])\n",
    "                        else: break\n",
    "                    else: break\n",
    "\n",
    "\n",
    "            elif len(final)==0:\n",
    "\n",
    "                for j in range(k):\n",
    "                    if len(final)!=k:\n",
    "                        final.append(content[j])\n",
    "                        if len(final)!=k:  \n",
    "                            final.append(collabarative[j])\n",
    "                        else: break\n",
    "                    else: break\n",
    "\n",
    "\n",
    "            \n",
    "            df1 = pd.DataFrame(movies, columns=['movie_id', 'title'])   \n",
    "            df1= df1[df1['movie_id'].isin(final)]\n",
    "            return df1\n",
    "\n",
    "        \n",
    "       \n",
    "        content_output= content_filtering(movies,user_id,k)\n",
    "        \n",
    "        collabrative_output = collabrative_filltering(ratings ,user_id,k)\n",
    "        \n",
    "        \n",
    "        result= Hybrid_Modelling(content_output, collabrative_output, movies, k)\n",
    "        print(result)\n",
    "        \n",
    "        \n",
    "        return\n",
    "    \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Object8= Recommender_System_Movies_DataSet(ratings, movies, users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1104, 1105, 1103, 1101, 1108, 1100, 1098, 1115, 1093, 1116]\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "item (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "User (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movie_emb (Embedding)           (None, 1, 3)         11121       item[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "user_emb (Embedding)            (None, 1, 3)         18123       User[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Movies (Flatten)        (None, 3)            0           movie_emb[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Flatten_Users (Flatten)         (None, 3)            0           user_emb[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Dot_Product (Dot)               (None, 1)            0           Flatten_Movies[0][0]             \n",
      "                                                                 Flatten_Users[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 29,244\n",
      "Trainable params: 29,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/30\n",
      "25006/25006 [==============================] - 28s 1ms/step - loss: 4.9226 - mae: 1.7438 - mse: 4.9226\n",
      "Epoch 2/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.9757 - mae: 0.7711 - mse: 0.9757\n",
      "Epoch 3/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.8743 - mae: 0.7353 - mse: 0.8743\n",
      "Epoch 4/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.8598 - mae: 0.7301 - mse: 0.8598: 4s  - ETA: 1s - \n",
      "Epoch 5/30\n",
      "25006/25006 [==============================] - 29s 1ms/step - loss: 0.8553 - mae: 0.7284 - mse: 0.8553\n",
      "Epoch 6/30\n",
      "25006/25006 [==============================] - 27s 1ms/step - loss: 0.8518 - mae: 0.7274 - mse: 0.8518\n",
      "Epoch 7/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.8477 - mae: 0.7255 - mse: 0.8477\n",
      "Epoch 8/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.8425 - mae: 0.7230 - mse: 0.8425\n",
      "Epoch 9/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.8332 - mae: 0.7189 - mse: 0.8332\n",
      "Epoch 10/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.8200 - mae: 0.7126 - mse: 0.8200\n",
      "Epoch 11/30\n",
      "25006/25006 [==============================] - 25s 1ms/step - loss: 0.8057 - mae: 0.7055 - mse: 0.8057\n",
      "Epoch 12/30\n",
      "25006/25006 [==============================] - 30s 1ms/step - loss: 0.7936 - mae: 0.6994 - mse: 0.7936\n",
      "Epoch 13/30\n",
      "25006/25006 [==============================] - 28s 1ms/step - loss: 0.7843 - mae: 0.6947 - mse: 0.7843\n",
      "Epoch 14/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.7773 - mae: 0.6912 - mse: 0.7773\n",
      "Epoch 15/30\n",
      "25006/25006 [==============================] - 28s 1ms/step - loss: 0.7725 - mae: 0.6886 - mse: 0.7725\n",
      "Epoch 16/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.7685 - mae: 0.6866 - mse: 0.7685\n",
      "Epoch 17/30\n",
      "25006/25006 [==============================] - 24s 969us/step - loss: 0.7655 - mae: 0.6848 - mse: 0.7655\n",
      "Epoch 18/30\n",
      "25006/25006 [==============================] - 28s 1ms/step - loss: 0.7631 - mae: 0.6837 - mse: 0.7631\n",
      "Epoch 19/30\n",
      "25006/25006 [==============================] - 28s 1ms/step - loss: 0.7613 - mae: 0.6827 - mse: 0.7613\n",
      "Epoch 20/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.7598 - mae: 0.6819 - mse: 0.7598\n",
      "Epoch 21/30\n",
      "25006/25006 [==============================] - 25s 983us/step - loss: 0.7586 - mae: 0.6813 - mse: 0.7586\n",
      "Epoch 22/30\n",
      "25006/25006 [==============================] - 25s 983us/step - loss: 0.7573 - mae: 0.6806 - mse: 0.7573\n",
      "Epoch 23/30\n",
      "25006/25006 [==============================] - 26s 1ms/step - loss: 0.7565 - mae: 0.6803 - mse: 0.7565\n",
      "Epoch 24/30\n",
      "25006/25006 [==============================] - 29s 1ms/step - loss: 0.7558 - mae: 0.6798 - mse: 0.7558\n",
      "Epoch 25/30\n",
      "25006/25006 [==============================] - 41s 2ms/step - loss: 0.7550 - mae: 0.6793 - mse: 0.7550\n",
      "Epoch 26/30\n",
      "25006/25006 [==============================] - 39s 2ms/step - loss: 0.7548 - mae: 0.6792 - mse: 0.7548\n",
      "Epoch 27/30\n",
      "25006/25006 [==============================] - 37s 1ms/step - loss: 0.7540 - mae: 0.6790 - mse: 0.7540\n",
      "Epoch 28/30\n",
      "25006/25006 [==============================] - 36s 1ms/step - loss: 0.7536 - mae: 0.6785 - mse: 0.7536\n",
      "Epoch 29/30\n",
      "25006/25006 [==============================] - 35s 1ms/step - loss: 0.7533 - mae: 0.6784 - mse: 0.7533\n",
      "Epoch 30/30\n",
      "25006/25006 [==============================] - 36s 1ms/step - loss: 0.7528 - mae: 0.6782 - mse: 0.7528\n",
      "0.6572869697363554\n",
      "0.6978511418603207\n",
      "[801, 974, 3010, 744, 628, 2787, 719, 1067, 3021, 2309]\n",
      "      movie_id                                      title\n",
      "628        628                            Denise Calls Up\n",
      "744        744  Gold Diggers: The Secret of Bear Mountain\n",
      "801        801                          Bewegte Mann, Der\n",
      "974        974                              Fly Away Home\n",
      "1101      1101        Eighth Day, The (Le Huiti�me jour )\n",
      "1103      1103                                     Drunks\n",
      "1104      1104                People vs. Larry Flynt, The\n",
      "1105      1105                                 Glory Daze\n",
      "1108      1108                             On Golden Pond\n",
      "3010      3010                             Mansfield Park\n"
     ]
    }
   ],
   "source": [
    "Object8.get_recommendations(0,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
